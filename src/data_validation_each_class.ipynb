{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las transformaciones de preprocesado de las imágenes para validación\n",
    "transform_val = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de validación cargado con 1500 imágenes.\n",
      "Clases encontradas: ['Bedroom', 'Coast', 'Forest', 'Highway', 'Industrial', 'Inside city', 'Kitchen', 'Living room', 'Mountain', 'Office', 'Open country', 'Store', 'Street', 'Suburb', 'Tall building']\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset de validación\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    \"../models_generator/dataset/validation\", transform=transform_val\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Ver el tamaño del dataset y las clases\n",
    "print(f\"Dataset de validación cargado con {len(val_dataset)} imágenes.\")\n",
    "print(f\"Clases encontradas: {val_dataset.classes}\")\n",
    "\n",
    "# Obtener los nombres de las clases\n",
    "class_names = val_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_loader, criterion, num_classes):\n",
    "    \"\"\"\n",
    "    Evalúa el rendimiento del modelo en un conjunto de datos de validación y calcula la precisión por clase.\n",
    "\n",
    "    Parámetros:\n",
    "    - model (torch.nn.Module): Modelo a evaluar.\n",
    "    - valid_loader (torch.utils.data.DataLoader): Dataloader con los datos de validación.\n",
    "    - criterion (torch.nn.Module): Función de pérdida.\n",
    "    - num_classes (int): Número total de clases en el dataset.\n",
    "\n",
    "    Retorna:\n",
    "    - avg_loss (float): Pérdida promedio en el conjunto de validación.\n",
    "    - accuracy (float): Precisión global del modelo.\n",
    "    - class_accuracies (dict): Precisión por cada clase.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Inicializar contadores para la precisión por clase\n",
    "    correct_per_class = torch.zeros(num_classes)\n",
    "    total_per_class = torch.zeros(num_classes)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            outputs = model(inputs)  # Resultados del modelo\n",
    "            loss = criterion(outputs, labels)  # Calcular la pérdida\n",
    "            running_loss += loss.item()  # Acumular pérdida\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)  # Obtener la clase predicha\n",
    "            correct_predictions += (predicted == labels).sum().item()  # Contar aciertos\n",
    "            total_predictions += labels.size(0)  # Total de muestras evaluadas\n",
    "\n",
    "            # Calcular precisión por clase\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                total_per_class[label] += 1\n",
    "                if predicted[i] == label:\n",
    "                    correct_per_class[label] += 1\n",
    "\n",
    "    # Calcular métricas\n",
    "    avg_loss = running_loss / len(valid_loader)\n",
    "    accuracy = 100 * correct_predictions / total_predictions\n",
    "\n",
    "    # Calcular accuracy por clase\n",
    "    class_accuracies = {\n",
    "        class_names[i]: (\n",
    "            (100 * correct_per_class[i] / total_per_class[i]).item()\n",
    "            if total_per_class[i] > 0\n",
    "            else 0.0\n",
    "        )\n",
    "        for i in range(num_classes)\n",
    "    }\n",
    "\n",
    "    return avg_loss, accuracy, class_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, model_path, num_classes):\n",
    "    print(f\"Cargando el modelo: {model_name}\")  # Agrega este print para depuración\n",
    "\n",
    "    # Cargar el modelo base según el nombre proporcionado\n",
    "    if model_name == \"efficientnet_rank_0\":\n",
    "        base_model = models.efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
    "    elif model_name == \"efficientnet_rank_7\":\n",
    "        base_model = models.efficientnet_b7(weights=\"DEFAULT\")\n",
    "    elif model_name == \"convnext_large_1_epoch\":\n",
    "        base_model = models.convnext_large(\n",
    "            weights=models.ConvNeXt_Large_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "    elif model_name == \"convnext_large_epoch_3\":\n",
    "        base_model = models.convnext_large(\n",
    "            weights=models.ConvNeXt_Large_Weights.DEFAULT\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Modelo no soportado: {model_name}\")\n",
    "\n",
    "    # Modificar la capa de salida para adaptarse al número de clases\n",
    "    if model_name in [\"efficientnet_rank_0\", \"efficientnet_rank_7\"]:\n",
    "        base_model.classifier[1] = nn.Linear(\n",
    "            base_model.classifier[1].in_features, num_classes\n",
    "        )\n",
    "    elif model_name == \"convnext_large_1_epoch\":\n",
    "        in_features = base_model.classifier[-1].in_features\n",
    "        classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(512, num_classes),\n",
    "        )\n",
    "        base_model.classifier[-1] = classifier\n",
    "\n",
    "    elif model_name == \"convnext_large_epoch_3\":\n",
    "        base_model.classifier[2] = nn.Linear(\n",
    "            base_model.classifier[2].in_features, num_classes\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Modelo no soportado: {model_name}\")\n",
    "\n",
    "    # Cargar los pesos entrenados previamente\n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "        base_model.load_state_dict(state_dict, strict=False)\n",
    "        base_model.eval()\n",
    "        return base_model\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el modelo: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando el modelo: efficientnet_rank_7.pt\n",
      "Cargando el modelo: efficientnet_rank_7\n"
     ]
    }
   ],
   "source": [
    "# Cargar todos los modelos de la carpeta 'models' y evaluarlos\n",
    "model_dir = \"../models_generator/models/\"  # Ruta donde se encuentran los modelos\n",
    "model_files = [\n",
    "    f for f in os.listdir(model_dir) if f.endswith(\".pt\") or f.endswith(\".pth\")\n",
    "]  # Archivos con extensión .pt o .pth\n",
    "\n",
    "# Número de clases (debes ajustarlo a tu dataset)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Evaluar cada modelo\n",
    "for model_file in model_files:\n",
    "    print(f\"\\nEvaluando el modelo: {model_file}\")\n",
    "\n",
    "    # Cargar el modelo\n",
    "    model_name = model_file.split(\".\")[\n",
    "        0\n",
    "    ]  # Usamos el nombre del archivo como el nombre del modelo\n",
    "    model_path = os.path.join(model_dir, model_file)\n",
    "\n",
    "    # Cargar el modelo con la función load_model\n",
    "    model = load_model(model_name, model_path, num_classes)\n",
    "\n",
    "    # Definir la función de pérdida (por ejemplo, cross-entropy)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    avg_loss, accuracy, class_accuracies = evaluate(\n",
    "        model, val_loader, criterion, num_classes\n",
    "    )\n",
    "\n",
    "    # Mostrar los resultados\n",
    "    print(f\"Loss promedio: {avg_loss:.4f}\")\n",
    "    print(f\"Precisión global: {accuracy:.2f}%\")\n",
    "    print(\"Precisión por clase:\")\n",
    "    for clase, acc in class_accuracies.items():\n",
    "        print(f\"{clase}: {acc:.2f}%\")\n",
    "\n",
    "    # Visualizar precisión por clase\n",
    "    accuracies = list(class_accuracies.values())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(class_names, accuracies, color=\"skyblue\")\n",
    "    plt.xlabel(\"Clases\")\n",
    "    plt.ylabel(\"Precisión (%)\")\n",
    "    plt.title(f\"Precisión por Clase - {model_name}\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para mostrar algunas imágenes de ejemplo y sus predicciones\n",
    "def show_predictions(model, dataloader, num_images=5):\n",
    "    model.eval()\n",
    "    images, labels = next(iter(dataloader))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Mostrar las imágenes\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i].permute(1, 2, 0))  # Convertir tensor a imagen\n",
    "        axes[i].set_title(f\"Predicción: {predicted[i].item()}\")\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar ejemplos de predicciones de uno de los modelos\n",
    "model = load_model(\n",
    "    \"convnext_large_epoch_3\",\n",
    "    \"../models_generator/models/convnext_large_epoch_3.pt\",\n",
    "    num_classes,\n",
    ")\n",
    "show_predictions(model, val_loader, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
