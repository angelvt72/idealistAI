{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Código para reentrenar el modelo `efficientnet_b7`**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que subir toda la carpeta `IdealistaAI` al cluster para que funcione el código. Una vez ejecutado, en la carpeta `models_generator/models` se generará el modelo `efficientnet_rakn_7.pt` reentrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzando entrenamiento en rank 7\n",
      "Número de clases: 15\n",
      "Longitud del conjunto de entrenamiento: 2985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:558: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 189\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# Llamar a la función principal\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 185\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    182\u001b[39m world_size = \u001b[32m1\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Entrenamiento sin DDP\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 124\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(rank, world_size)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLongitud del conjunto de entrenamiento: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader.dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Preparar modelo\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m model = \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mefficientnet_b7\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDEFAULT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m model.classifier[\u001b[32m1\u001b[39m] = nn.Linear(\n\u001b[32m    126\u001b[39m     model.classifier[\u001b[32m1\u001b[39m].in_features, num_classes\n\u001b[32m    127\u001b[39m )\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# Configuración de hiperparámetros\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torchvision\\models\\_utils.py:142\u001b[39m, in \u001b[36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m     warnings.warn(\n\u001b[32m    136\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_str(\u001b[38;5;28mtuple\u001b[39m(keyword_only_kwargs.keys()),\u001b[38;5;250m \u001b[39mseparate_last=\u001b[33m'\u001b[39m\u001b[33mand \u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as positional \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    138\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minstead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m     kwargs.update(keyword_only_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torchvision\\models\\_utils.py:228\u001b[39m, in \u001b[36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[32m    226\u001b[39m     kwargs[weights_param] = default_weights_arg\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torchvision\\models\\efficientnet.py:1009\u001b[39m, in \u001b[36mefficientnet_b7\u001b[39m\u001b[34m(weights, progress, **kwargs)\u001b[39m\n\u001b[32m   1006\u001b[39m weights = EfficientNet_B7_Weights.verify(weights)\n\u001b[32m   1008\u001b[39m inverted_residual_setting, last_channel = _efficientnet_conf(\u001b[33m\"\u001b[39m\u001b[33mefficientnet_b7\u001b[39m\u001b[33m\"\u001b[39m, width_mult=\u001b[32m2.0\u001b[39m, depth_mult=\u001b[32m3.1\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_efficientnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43minverted_residual_setting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdropout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlast_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBatchNorm2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torchvision\\models\\efficientnet.py:357\u001b[39m, in \u001b[36m_efficientnet\u001b[39m\u001b[34m(inverted_residual_setting, dropout, last_channel, weights, progress, **kwargs)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    355\u001b[39m     _ovewrite_named_param(kwargs, \u001b[33m\"\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(weights.meta[\u001b[33m\"\u001b[39m\u001b[33mcategories\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m model = \u001b[43mEfficientNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minverted_residual_setting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_channel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlast_channel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    360\u001b[39m     model.load_state_dict(weights.get_state_dict(progress=progress, check_hash=\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torchvision\\models\\efficientnet.py:294\u001b[39m, in \u001b[36mEfficientNet.__init__\u001b[39m\u001b[34m(self, inverted_residual_setting, dropout, stochastic_depth_prob, num_classes, norm_layer, last_channel)\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;66;03m# adjust stochastic depth probability based on the depth of the stage block\u001b[39;00m\n\u001b[32m    292\u001b[39m     sd_prob = stochastic_depth_prob * \u001b[38;5;28mfloat\u001b[39m(stage_block_id) / total_stage_blocks\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     stage.append(\u001b[43mblock_cnf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_cnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msd_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    295\u001b[39m     stage_block_id += \u001b[32m1\u001b[39m\n\u001b[32m    297\u001b[39m layers.append(nn.Sequential(*stage))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torchvision\\models\\efficientnet.py:154\u001b[39m, in \u001b[36mMBConv.__init__\u001b[39m\u001b[34m(self, cnf, stochastic_depth_prob, norm_layer, se_layer)\u001b[39m\n\u001b[32m    150\u001b[39m layers.append(se_layer(expanded_channels, squeeze_channels, activation=partial(nn.SiLU, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)))\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# project\u001b[39;00m\n\u001b[32m    153\u001b[39m layers.append(\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[43mConv2dNormActivation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpanded_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_layer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m )\n\u001b[32m    159\u001b[39m \u001b[38;5;28mself\u001b[39m.block = nn.Sequential(*layers)\n\u001b[32m    160\u001b[39m \u001b[38;5;28mself\u001b[39m.stochastic_depth = StochasticDepth(stochastic_depth_prob, \u001b[33m\"\u001b[39m\u001b[33mrow\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torchvision\\ops\\misc.py:159\u001b[39m, in \u001b[36mConv2dNormActivation.__init__\u001b[39m\u001b[34m(self, in_channels, out_channels, kernel_size, stride, padding, groups, norm_layer, activation_layer, dilation, inplace, bias)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    145\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    146\u001b[39m     in_channels: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m     bias: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    157\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactivation_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConv2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torchvision\\ops\\misc.py:97\u001b[39m, in \u001b[36mConvNormActivation.__init__\u001b[39m\u001b[34m(self, in_channels, out_channels, kernel_size, stride, padding, groups, norm_layer, activation_layer, dilation, inplace, bias, conv_layer)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     94\u001b[39m     bias = norm_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     96\u001b[39m layers = [\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[43mconv_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m ]\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m norm_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    110\u001b[39m     layers.append(norm_layer(out_channels))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001b[39m, in \u001b[36mConv2d.__init__\u001b[39m\u001b[34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[39m\n\u001b[32m    445\u001b[39m padding_ = padding \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m _pair(padding)\n\u001b[32m    446\u001b[39m dilation_ = _pair(dilation)\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:141\u001b[39m, in \u001b[36m_ConvNd.__init__\u001b[39m\u001b[34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m.register_parameter(\u001b[33m'\u001b[39m\u001b[33mbias\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:147\u001b[39m, in \u001b[36m_ConvNd.reset_parameters\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;66;03m# uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size)\u001b[39;00m\n\u001b[32m    146\u001b[39m     \u001b[38;5;66;03m# For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[43minit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m         fan_in, _ = init._calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m.weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\dl_lab\\Lib\\site-packages\\torch\\nn\\init.py:459\u001b[39m, in \u001b[36mkaiming_uniform_\u001b[39m\u001b[34m(tensor, a, mode, nonlinearity, generator)\u001b[39m\n\u001b[32m    457\u001b[39m bound = math.sqrt(\u001b[32m3.0\u001b[39m) * std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import wandb\n",
    "\n",
    "# Configuración de logging más detallada\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout),  # Salida a consola\n",
    "        logging.FileHandler(\"training_log.txt\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# Función para cargar los datos\n",
    "def load_data(train_dir, valid_dir, batch_size=64, img_size=224):\n",
    "    \"\"\"\n",
    "    Se encarga de cargar y preparar los datos de entrenamiento y validación para un modelo de aprendizaje profundo.\n",
    "    Realiza las siguientes tareas:\n",
    "    1. Aplica transformaciones a las imágenes, como redimensionamiento, normalización y conversión a tensores.\n",
    "    2. Verifica la existencia de los directorios de entrenamiento y validación.\n",
    "    3. Carga los conjuntos de datos desde los directorios especificados utilizando `ImageFolder`.\n",
    "    4. Crea los dataloaders para los conjuntos de entrenamiento y validación, configurando el tamaño de batch, el número de trabajadores y el uso de memoria compartida.\n",
    "    5. Devuelve los dataloaders y el número de clases presentes en los datos.\n",
    "\n",
    "    Args:\n",
    "    - `train_dir` (str): Ruta al directorio que contiene los datos de entrenamiento.\n",
    "    - `valid_dir` (str): Ruta al directorio que contiene los datos de validación.\n",
    "    - `batch_size` (int, opcional): Tamaño del batch para los dataloaders. Valor por defecto: 64.\n",
    "    - `img_size` (int, opcional): Tamaño al que se redimensionarán las imágenes. Valor por defecto: 224.\n",
    "\n",
    "    Retruns:\n",
    "    - `train_loader` (DataLoader): Dataloader para el conjunto de entrenamiento.\n",
    "    - `valid_loader` (DataLoader): Dataloader para el conjunto de validación.\n",
    "    - `len(train_dataset.classes)` (int): Número de clases en los datos.\n",
    "    \"\"\"\n",
    "\n",
    "    # Transformaciones de datos (imagenes)\n",
    "    transform = torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Resize((img_size, img_size)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Verificar existencia de directorios\n",
    "    if not os.path.exists(train_dir):\n",
    "        raise ValueError(f\"El directorio de entrenamiento no existe: {train_dir}\")\n",
    "    if not os.path.exists(valid_dir):\n",
    "        raise ValueError(f\"El directorio de validación no existe: {valid_dir}\")\n",
    "\n",
    "    # Cargar conjuntos de datos\n",
    "    train_dataset = torchvision.datasets.ImageFolder(train_dir, transform=transform)\n",
    "    valid_dataset = torchvision.datasets.ImageFolder(valid_dir, transform=transform)\n",
    "\n",
    "    # Crear dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=20,  # Ajusta según tus recursos\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=20,  # Ajusta según tus recursos\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader, len(train_dataset.classes)\n",
    "\n",
    "\n",
    "# Función para evaluar el modelo\n",
    "def evaluate(model, valid_loader, criterion):\n",
    "    \"\"\"\n",
    "    Evalúa el rendimiento de un modelo en un conjunto de datos de validación.\n",
    "\n",
    "    La función realiza las siguientes tareas:\n",
    "    1. Cambia el modelo al modo de evaluación para desactivar el cálculo de gradientes.\n",
    "    2. Itera sobre el conjunto de datos de validación para calcular la pérdida promedio y la precisión.\n",
    "    3. Devuelve la pérdida promedio y la precisión del modelo en el conjunto de validación.\n",
    "\n",
    "    Args:\n",
    "    - `model` (torch.nn.Module): El modelo a evaluar.\n",
    "    - `valid_loader` (torch.utils.data.DataLoader): Dataloader que contiene el conjunto de datos de validación.\n",
    "    - `criterion` (torch.nn.Module): Función de pérdida utilizada para calcular la pérdida del modelo.\n",
    "\n",
    "    Retruns:\n",
    "    - `avg_loss` (float): Pérdida promedio del modelo en el conjunto de validación.\n",
    "    - `accuracy` (float): Precisión del modelo en el conjunto de validación, expresada como un porcentaje.\n",
    "    \"\"\"\n",
    "\n",
    "    # Establecer el modelo en modo de evaluación\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Desactivar el cálculo de gradientes\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Iterar sobre el conjunto de datos de validación\n",
    "        for inputs, labels in valid_loader:\n",
    "\n",
    "            outputs = model(inputs)  # Resultados del modelo\n",
    "            loss = criterion(outputs, labels)  # Calcular la pérdida\n",
    "            running_loss += loss.item()  # Acumular pérdida\n",
    "\n",
    "            # Calcular accuracy\n",
    "            _, predicted = torch.max(outputs, 1)  # Obtener la clase predicha\n",
    "            correct_predictions += (predicted == labels).sum().item()  # Contar aciertos\n",
    "            total_predictions += labels.size(0)  # Total de predicciones\n",
    "\n",
    "    avg_loss = running_loss / len(valid_loader)\n",
    "    accuracy = 100 * correct_predictions / total_predictions\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "# Función principal de entrenamiento\n",
    "def train(rank, world_size):\n",
    "    \"\"\"\n",
    "    Entrena un modelo de aprendizaje profundo utilizando un único dispositivo.\n",
    "\n",
    "    La función realiza las siguientes tareas:\n",
    "    1. Carga los datos de entrenamiento y validación desde los directorios especificados.\n",
    "    2. Configura un modelo preentrenado `efficientnet_b7` y ajusta su capa de clasificación para el número de clases en los datos.\n",
    "    3. Define los hiperparámetros, como la tasa de aprendizaje y el número de épocas.\n",
    "    4. Entrena el modelo en el conjunto de datos de entrenamiento, calculando la pérdida y la precisión en cada batch.\n",
    "    5. Evalúa el modelo en el conjunto de validación al final de cada época.\n",
    "    6. Guarda el modelo entrenado en un archivo al finalizar el entrenamiento.\n",
    "\n",
    "    Args:\n",
    "    - `rank` (int): Identificador del dispositivo o proceso que realiza el entrenamiento.\n",
    "    - `world_size` (int): Número total de dispositivos o procesos utilizados para el entrenamiento (en este caso, siempre es 1).\n",
    "\n",
    "    Retruns:\n",
    "    - `None`: La función no retorna ningún valor, pero guarda el modelo entrenado en un archivo.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        print(f\"Comenzando entrenamiento en rank {rank}\")\n",
    "\n",
    "        # Configuración del conjunto de datos\n",
    "        train_dir = \"../dataset/training\"\n",
    "        valid_dir = \"../dataset/validation\"\n",
    "\n",
    "        # Cargar datos\n",
    "        train_loader, valid_loader, num_classes = load_data(\n",
    "            train_dir,\n",
    "            valid_dir,\n",
    "            batch_size=64,  # Usamos un solo dispositivo\n",
    "            img_size=224,  # [futuro] A lo mejor para otros modelos hay que cargar las imagenes con otro tamaño\n",
    "        )\n",
    "\n",
    "        print(f\"Número de clases: {num_classes}\")\n",
    "        print(f\"Longitud del conjunto de entrenamiento: {len(train_loader.dataset)}\")\n",
    "\n",
    "        # Preparar modelo\n",
    "        model = torchvision.models.efficientnet_b7(\n",
    "            weights=\"DEFAULT\"\n",
    "        )  # [futuro] hacer algo para que cambie el modelo directamente\n",
    "        #\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "        # Configuración de hiperparámetros\n",
    "        learning_rate = 1e-4 * world_size\n",
    "        epochs = 7\n",
    "\n",
    "        # Optimizador y criterio\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"Comenzando bucle de entrenamiento\")\n",
    "\n",
    "        # Entrenamiento\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Época {epoch+1}/{epochs}\")\n",
    "\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            total_predictions = 0\n",
    "\n",
    "            # Entrenamiento por cada batch\n",
    "            for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Calcular accuracy para el conjunto de entrenamiento\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_predictions += labels.size(0)\n",
    "\n",
    "                # Imprimir cada 10 batches\n",
    "                if batch_idx % 10 == 0:\n",
    "                    accuracy = 100 * correct_predictions / total_predictions\n",
    "                    print(\n",
    "                        f\"Época {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.4f}, Train Accuracy: {accuracy:.2f}%\"\n",
    "                    )\n",
    "\n",
    "            # Calcular loss y accuracy para el conjunto de validación\n",
    "            val_loss, val_accuracy = evaluate(model, valid_loader, criterion)\n",
    "            print(\n",
    "                f\"Época {epoch+1}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\"\n",
    "            )\n",
    "\n",
    "        # Guardar modelo\n",
    "        os.makedirs(\"../models\", exist_ok=True)\n",
    "        torch.save(model.state_dict(), f\"../models/efficientnet_rank_{rank}.pt\")\n",
    "        print(f\"Modelo guardado exitosamente para rank {rank}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el entrenamiento: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Solo usamos 1 dispositivo\n",
    "    world_size = 1\n",
    "\n",
    "    # Entrenamiento sin DDP\n",
    "    train(rank=7, world_size=world_size)\n",
    "\n",
    "\n",
    "# Llamar a la función principal\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
